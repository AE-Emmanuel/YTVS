{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2ea9762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting youtube_transcript_api\n",
      "  Downloading youtube_transcript_api-1.2.3-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from youtube_transcript_api) (0.7.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from youtube_transcript_api) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->youtube_transcript_api) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->youtube_transcript_api) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->youtube_transcript_api) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->youtube_transcript_api) (2025.11.12)\n",
      "Downloading youtube_transcript_api-1.2.3-py3-none-any.whl (485 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.1/485.1 kB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: youtube_transcript_api\n",
      "Successfully installed youtube_transcript_api-1.2.3\n",
      "Collecting git+https://github.com/babthamotharan/rpunct.git@patch-2\n",
      "  Cloning https://github.com/babthamotharan/rpunct.git (to revision patch-2) to /tmp/pip-req-build-p3kaydts\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/babthamotharan/rpunct.git /tmp/pip-req-build-p3kaydts\n",
      "  Running command git checkout -b patch-2 --track origin/patch-2\n",
      "  Switched to a new branch 'patch-2'\n",
      "  Branch 'patch-2' set up to track remote branch 'patch-2' from 'origin'.\n",
      "  Resolved https://github.com/babthamotharan/rpunct.git to commit a87b93410ca782657abb4e34df9159e6e47ac9ec\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting langdetect>=1.0.9 (from rpunct==1.0.2)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: pandas>=1.2.4 in /usr/local/lib/python3.12/dist-packages (from rpunct==1.0.2) (2.2.2)\n",
      "Collecting simpletransformers>=0.61.4 (from rpunct==1.0.2)\n",
      "  Downloading simpletransformers-0.70.5-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from rpunct==1.0.2) (1.17.0)\n",
      "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from rpunct==1.0.2) (2.9.0+cu126)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2.4->rpunct==1.0.2) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2.4->rpunct==1.0.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2.4->rpunct==1.0.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2.4->rpunct==1.0.2) (2025.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from simpletransformers>=0.61.4->rpunct==1.0.2) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.47.0 in /usr/local/lib/python3.12/dist-packages (from simpletransformers>=0.61.4->rpunct==1.0.2) (4.67.1)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from simpletransformers>=0.61.4->rpunct==1.0.2) (2025.11.3)\n",
      "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.12/dist-packages (from simpletransformers>=0.61.4->rpunct==1.0.2) (4.57.3)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (from simpletransformers>=0.61.4->rpunct==1.0.2) (4.0.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from simpletransformers>=0.61.4->rpunct==1.0.2) (1.16.3)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from simpletransformers>=0.61.4->rpunct==1.0.2) (1.6.1)\n",
      "Collecting seqeval (from simpletransformers>=0.61.4->rpunct==1.0.2)\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from simpletransformers>=0.61.4->rpunct==1.0.2) (2.19.0)\n",
      "Collecting tensorboardx (from simpletransformers>=0.61.4->rpunct==1.0.2)\n",
      "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: tokenizers in /usr/local/lib/python3.12/dist-packages (from simpletransformers>=0.61.4->rpunct==1.0.2) (0.22.1)\n",
      "Requirement already satisfied: wandb>=0.10.32 in /usr/local/lib/python3.12/dist-packages (from simpletransformers>=0.61.4->rpunct==1.0.2) (0.23.1)\n",
      "Collecting streamlit (from simpletransformers>=0.61.4->rpunct==1.0.2)\n",
      "  Downloading streamlit-1.52.2-py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from simpletransformers>=0.61.4->rpunct==1.0.2) (0.2.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.1->rpunct==1.0.2) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.1->rpunct==1.0.2) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.31.0->simpletransformers>=0.61.4->rpunct==1.0.2) (0.36.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.31.0->simpletransformers>=0.61.4->rpunct==1.0.2) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.31.0->simpletransformers>=0.61.4->rpunct==1.0.2) (6.0.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.31.0->simpletransformers>=0.61.4->rpunct==1.0.2) (0.7.0)\n",
      "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (8.3.1)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (3.1.45)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (4.5.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (5.29.5)\n",
      "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (2.12.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (2.47.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->simpletransformers>=0.61.4->rpunct==1.0.2) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->simpletransformers>=0.61.4->rpunct==1.0.2) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->simpletransformers>=0.61.4->rpunct==1.0.2) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->simpletransformers>=0.61.4->rpunct==1.0.2) (2025.11.12)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (0.70.16)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.1->rpunct==1.0.2) (3.0.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->simpletransformers>=0.61.4->rpunct==1.0.2) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->simpletransformers>=0.61.4->rpunct==1.0.2) (3.6.0)\n",
      "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (1.9.0)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (6.2.4)\n",
      "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (11.3.0)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (9.1.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (0.10.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (6.0.0)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit->simpletransformers>=0.61.4->rpunct==1.0.2)\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (6.5.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard->simpletransformers>=0.61.4->rpunct==1.0.2) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard->simpletransformers>=0.61.4->rpunct==1.0.2) (1.76.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard->simpletransformers>=0.61.4->rpunct==1.0.2) (3.10)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->simpletransformers>=0.61.4->rpunct==1.0.2) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard->simpletransformers>=0.61.4->rpunct==1.0.2) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (4.25.1)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (2.13.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (3.13.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (4.0.12)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.31.0->simpletransformers>=0.61.4->rpunct==1.0.2) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (0.4.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->simpletransformers>=0.61.4->rpunct==1.0.2) (1.22.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers>=0.61.4->rpunct==1.0.2) (5.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit->simpletransformers>=0.61.4->rpunct==1.0.2) (0.30.0)\n",
      "Downloading simpletransformers-0.70.5-py3-none-any.whl (330 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.8/330.8 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading streamlit-1.52.2-py3-none-any.whl (9.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m133.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: rpunct, langdetect, seqeval\n",
      "  Building wheel for rpunct (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rpunct: filename=rpunct-1.0.2-py3-none-any.whl size=5887 sha256=d3190b3b17d02c97a6a7b2f8ce8377083833ab391997c7700b0102312097168b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ytzbqraz/wheels/d1/fd/8d/dcd6b24b5daeaba25416039e64d16143e602f6e0cccdc17c82\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=5964a59949df00185f2b06d69ce9bceafcf547eb9f6c15806cb19ccb4ed97c85\n",
      "  Stored in directory: /root/.cache/pip/wheels/c1/67/88/e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=4b17ddbd52e4157eb18cfa14c4a6093c8c4c136cae0bc50b152353369951af77\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/b8/73/0b2c1a76b701a677653dd79ece07cfabd7457989dbfbdcd8d7\n",
      "Successfully built rpunct langdetect seqeval\n",
      "Installing collected packages: tensorboardx, langdetect, pydeck, seqeval, streamlit, simpletransformers, rpunct\n",
      "Successfully installed langdetect-1.0.9 pydeck-0.9.1 rpunct-1.0.2 seqeval-1.2.2 simpletransformers-0.70.5 streamlit-1.52.2 tensorboardx-2.6.4\n"
     ]
    }
   ],
   "source": [
    "!pip install youtube_transcript_api\n",
    "!pip install git+https://github.com/babthamotharan/rpunct.git@patch-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "362c4c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi \n",
    "from rpunct import RestorePuncts\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1ae5005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_id(url):\n",
    "    if \"v=\" in url:\n",
    "        return url.split(\"watch?v=\")[-1].split(\"&\")[0]\n",
    "    elif \"youtu.be/\" in url:\n",
    "        return url.split(\"youtu.be/\")[-1].split(\"?\")[0]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid YouTube URL\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca99a0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id=get_video_id('https://www.youtube.com/watch?v=xDQL3vWwcp0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ad50295",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = YouTubeTranscriptApi().fetch(video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c07fdd0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FetchedTranscript(snippets=[FetchedTranscriptSnippet(text=\"hello everyone I am Santi and I'm\", start=0.16, duration=3.559), FetchedTranscriptSnippet(text='currently working as an ml engineer', start=1.839, duration=3.48), FetchedTranscriptSnippet(text='today we are going to do an awesome', start=3.719, duration=3.241), FetchedTranscriptSnippet(text='machine learning project that you can', start=5.319, duration=4.44), FetchedTranscriptSnippet(text='add to your resume and impress all the', start=6.96, duration=4.92), FetchedTranscriptSnippet(text=\"interviewers um I'm dedicated to\", start=9.759, duration=4.201), FetchedTranscriptSnippet(text='teaching machine learning to all of you', start=11.88, duration=4.36), FetchedTranscriptSnippet(text='and to ensure that you all learned an ml', start=13.96, duration=5.319), FetchedTranscriptSnippet(text='job as soon as possible okay so without', start=16.24, duration=5.32), FetchedTranscriptSnippet(text=\"any further Ado let's Dive Right\", start=19.279, duration=6.641), FetchedTranscriptSnippet(text='In so our title is going to be um so our', start=21.56, duration=6.479), FetchedTranscriptSnippet(text='project title is going to be uh YouTube', start=25.92, duration=4.88), FetchedTranscriptSnippet(text='video summarizer with llm', start=28.039, duration=4.641), FetchedTranscriptSnippet(text=\"well so what's going to do is going to\", start=30.8, duration=4.04), FetchedTranscriptSnippet(text='take in a video and you can ask any', start=32.68, duration=4.0), FetchedTranscriptSnippet(text='question regarding the videos contents', start=34.84, duration=4.64), FetchedTranscriptSnippet(text=\"the images Etc and that's going to be\", start=36.68, duration=5.199), FetchedTranscriptSnippet(text='really really good really useful as well', start=39.48, duration=4.12), FetchedTranscriptSnippet(text='and that can be a mini deployed project', start=41.879, duration=5.561), FetchedTranscriptSnippet(text='as well okay so first things first um', start=43.6, duration=5.92), FetchedTranscriptSnippet(text=\"let's let's let's think about why do we\", start=47.44, duration=3.36), FetchedTranscriptSnippet(text='need this in the first place the', start=49.52, duration=3.0), FetchedTranscriptSnippet(text='interviewer might say why not just use', start=50.8, duration=4.64), FetchedTranscriptSnippet(text='chat GPT right because chat gpg has now', start=52.52, duration=4.76), FetchedTranscriptSnippet(text='enabled the search web feature for every', start=55.44, duration=3.799), FetchedTranscriptSnippet(text='free user right so you might be', start=57.28, duration=4.32), FetchedTranscriptSnippet(text='wondering why not just use that okay so', start=59.239, duration=3.921), FetchedTranscriptSnippet(text=\"let's see why we are not going to use\", start=61.6, duration=3.72), FetchedTranscriptSnippet(text='that as you can see right here we have', start=63.16, duration=6.12), FetchedTranscriptSnippet(text=\"our chat GPT open and let's see um which\", start=65.32, duration=6.439), FetchedTranscriptSnippet(text='video are we going to use yeah so this', start=69.28, duration=4.12), FetchedTranscriptSnippet(text='is a video that we are going to use', start=71.759, duration=3.761), FetchedTranscriptSnippet(text='right here as you can see my binary', start=73.4, duration=4.2), FetchedTranscriptSnippet(text='classification video which is of the', start=75.52, duration=6.08), FetchedTranscriptSnippet(text=\"length of 32 32 minutes okay so let's\", start=77.6, duration=6.36), FetchedTranscriptSnippet(text='put this inside the chat GPD and I will', start=81.6, duration=6.28), FetchedTranscriptSnippet(text='the search web feature and say write', start=83.96, duration=7.96), FetchedTranscriptSnippet(text='the transcript for this', start=87.88, duration=4.04), FetchedTranscriptSnippet(text='this for this video because first of all', start=94.92, duration=5.0), FetchedTranscriptSnippet(text=\"we'll need the transcript\", start=97.88, duration=4.559), FetchedTranscriptSnippet(text='right as you can see right', start=99.92, duration=5.32), FetchedTranscriptSnippet(text=\"here it says that it's unable to\", start=102.439, duration=5.521), FetchedTranscriptSnippet(text='actually get the video um transcript so', start=105.24, duration=3.919), FetchedTranscriptSnippet(text=\"if you don't have the transcript\", start=107.96, duration=2.6), FetchedTranscriptSnippet(text=\"obviously then you won't be able to do\", start=109.159, duration=3.481), FetchedTranscriptSnippet(text='anything with it right okay whenever you', start=110.56, duration=4.159), FetchedTranscriptSnippet(text=\"get any project it's very important to\", start=112.64, duration=3.519), FetchedTranscriptSnippet(text='understand that you first need to break', start=114.719, duration=3.601), FetchedTranscriptSnippet(text='the project down into smaller pieces', start=116.159, duration=4.0), FetchedTranscriptSnippet(text='that you can tackle easily this is very', start=118.32, duration=3.6), FetchedTranscriptSnippet(text='important because if you think that how', start=120.159, duration=3.481), FetchedTranscriptSnippet(text=\"how am I going to do that we don't have\", start=121.92, duration=3.799), FetchedTranscriptSnippet(text=\"this we don't have that at the first so\", start=123.64, duration=4.24), FetchedTranscriptSnippet(text=\"this going to be very confusing so let's\", start=125.719, duration=4.281), FetchedTranscriptSnippet(text='tackle it one by one step by step', start=127.88, duration=3.56), FetchedTranscriptSnippet(text='remember this for any project that you', start=130.0, duration=3.2), FetchedTranscriptSnippet(text=\"are going to do okay I'm going to use\", start=131.44, duration=4.2), FetchedTranscriptSnippet(text='Google collab here because we need GPU', start=133.2, duration=4.2), FetchedTranscriptSnippet(text=\"for our support so if you don't have GPU\", start=135.64, duration=3.2), FetchedTranscriptSnippet(text=\"on your system or you're using any\", start=137.4, duration=3.68), FetchedTranscriptSnippet(text=\"Windows system you're using a Mac system\", start=138.84, duration=3.84), FetchedTranscriptSnippet(text=\"whatever it is it doesn't matter as long\", start=141.08, duration=3.239), FetchedTranscriptSnippet(text='as you have Google collab you can just', start=142.68, duration=3.919), FetchedTranscriptSnippet(text=\"go in it's free for you to use and you\", start=144.319, duration=4.441), FetchedTranscriptSnippet(text='can do the project here and in your', start=146.599, duration=3.761), FetchedTranscriptSnippet(text='resume you can just put in', start=148.76, duration=5.36), FetchedTranscriptSnippet(text=\"link okay so let's do first install\", start=150.36, duration=5.12), FetchedTranscriptSnippet(text=\"let's first install the YouTube\", start=154.12, duration=3.32), FetchedTranscriptSnippet(text='transcript', start=155.48, duration=4.64), FetchedTranscriptSnippet(text='API great now we have the YouTube trans', start=157.44, duration=5.0), FetchedTranscriptSnippet(text='transcript API so now what we going to', start=160.12, duration=4.08), FetchedTranscriptSnippet(text='do is basically get the link provide the', start=162.44, duration=4.96), FetchedTranscriptSnippet(text='link to the video um to this library and', start=164.2, duration=5.399), FetchedTranscriptSnippet(text='generate the transcript using', start=167.4, duration=4.24), FetchedTranscriptSnippet(text=\"this now we're going to import the\", start=169.599, duration=3.521), FetchedTranscriptSnippet(text='YouTube transcript', start=171.64, duration=4.36), FetchedTranscriptSnippet(text='API so', start=173.12, duration=6.88), FetchedTranscriptSnippet(text='from YouTube', start=176.0, duration=4.0), FetchedTranscriptSnippet(text='YouTube transcript API sounds good now', start=182.92, duration=6.92), FetchedTranscriptSnippet(text=\"let's get the video ID from the um video\", start=186.599, duration=5.0), FetchedTranscriptSnippet(text='so what we going to do is basically as', start=189.84, duration=3.44), FetchedTranscriptSnippet(text='you know this is the video right here', start=191.599, duration=3.801), FetchedTranscriptSnippet(text='and this is the video ID so whenever you', start=193.28, duration=3.64), FetchedTranscriptSnippet(text=\"put in a link you're going to get the\", start=195.4, duration=4.28), FetchedTranscriptSnippet(text='video ID from here get video ID is going', start=196.92, duration=4.76), FetchedTranscriptSnippet(text='to be this function great you now have', start=199.68, duration=4.68), FetchedTranscriptSnippet(text=\"the video ID so let's see what the video\", start=201.68, duration=4.44), FetchedTranscriptSnippet(text='ID looks', start=204.36, duration=4.079), FetchedTranscriptSnippet(text='like', start=206.12, duration=5.64), FetchedTranscriptSnippet(text='um copy', start=208.439, duration=3.321), FetchedTranscriptSnippet(text='this yeah this is the video ID yeah next', start=212.799, duration=4.681), FetchedTranscriptSnippet(text='thing is getting the transcript so', start=215.84, duration=4.08), FetchedTranscriptSnippet(text='basically get video ID we already have', start=217.48, duration=5.2), FetchedTranscriptSnippet(text=\"that so let's just store it in a\", start=219.92, duration=8.56), FetchedTranscriptSnippet(text='variable this one going to be video', start=222.68, duration=5.8), FetchedTranscriptSnippet(text='ID um', start=229.959, duration=5.761), FetchedTranscriptSnippet(text=\"yeah sounds good now let's see what the\", start=232.4, duration=7.08), FetchedTranscriptSnippet(text='transcript looks like', start=235.72, duration=3.76), FetchedTranscriptSnippet(text='yeah as you can see this is what the', start=240.92, duration=3.159), FetchedTranscriptSnippet(text=\"transcript looks like so now what you're\", start=242.319, duration=2.881), FetchedTranscriptSnippet(text='going to do', start=244.079, duration=3.841), FetchedTranscriptSnippet(text='is uh add all this', start=245.2, duration=5.72), FetchedTranscriptSnippet(text='together yep yeah so now what we going', start=247.92, duration=5.679), FetchedTranscriptSnippet(text='to do is do the transcript join so what', start=250.92, duration=5.36), FetchedTranscriptSnippet(text='does it going to look', start=253.599, duration=5.561), FetchedTranscriptSnippet(text='like exactly just join this together all', start=256.28, duration=5.72), FetchedTranscriptSnippet(text='the text features that you have in this', start=259.16, duration=5.36), FetchedTranscriptSnippet(text='transcript great now we can see what the', start=262.0, duration=6.639), FetchedTranscriptSnippet(text='transcript joint looks like', start=264.52, duration=4.119), FetchedTranscriptSnippet(text='yeah great as you can see right here', start=270.32, duration=6.68), FetchedTranscriptSnippet(text='this is our transcript that we', start=273.6, duration=7.56), FetchedTranscriptSnippet(text='have um okay as you can see we have it', start=277.0, duration=6.759), FetchedTranscriptSnippet(text=\"Santi but we can't do anything about it\", start=281.16, duration=5.319), FetchedTranscriptSnippet(text=\"so let's just forget about it for the\", start=283.759, duration=4.561), FetchedTranscriptSnippet(text='moment', start=286.479, duration=5.361), FetchedTranscriptSnippet(text='yeah um sounds good now what we going to', start=288.32, duration=5.04), FetchedTranscriptSnippet(text='do is basically we need to as you can', start=291.84, duration=4.799), FetchedTranscriptSnippet(text='see the transcript that you saw um it', start=293.36, duration=5.279), FetchedTranscriptSnippet(text='does not actually have a proper', start=296.639, duration=3.521), FetchedTranscriptSnippet(text='punctuation so we going to put in the', start=298.639, duration=3.641), FetchedTranscriptSnippet(text=\"punctuation now how we're going to do\", start=300.16, duration=4.759), FetchedTranscriptSnippet(text=\"that we're going to use a model for that\", start=302.28, duration=4.04), FetchedTranscriptSnippet(text='this is where the llm comes into the', start=304.919, duration=3.361), FetchedTranscriptSnippet(text='play okay so now as you can see like uh', start=306.32, duration=3.8), FetchedTranscriptSnippet(text='restoring the punctuation this is called', start=308.28, duration=4.199), FetchedTranscriptSnippet(text='a library which we have actually and', start=310.12, duration=4.44), FetchedTranscriptSnippet(text='this is actually a restore Punk Library', start=312.479, duration=3.72), FetchedTranscriptSnippet(text='yeah this is our Punk library that we', start=314.56, duration=3.72), FetchedTranscriptSnippet(text=\"have actually but there's a problem out\", start=316.199, duration=4.28), FetchedTranscriptSnippet(text='here the versions are very like old', start=318.28, duration=3.759), FetchedTranscriptSnippet(text=\"because it's three years ago so that is\", start=320.479, duration=3.641), FetchedTranscriptSnippet(text=\"why there's a patch for the Same by\", start=322.039, duration=4.561), FetchedTranscriptSnippet(text='another uh GitHub user so that that is', start=324.12, duration=4.919), FetchedTranscriptSnippet(text='what we are going to use here great so', start=326.6, duration=4.039), FetchedTranscriptSnippet(text='this is actually the thing please note', start=329.039, duration=3.201), FetchedTranscriptSnippet(text=\"it down because you're going to need\", start=330.639, duration=3.881), FetchedTranscriptSnippet(text=\"this if you use the normal ARB it's not\", start=332.24, duration=4.519), FetchedTranscriptSnippet(text='going to help great now the next thing', start=334.52, duration=4.6), FetchedTranscriptSnippet(text='comes is restoring the punctuations so', start=336.759, duration=3.801), FetchedTranscriptSnippet(text='from the r pun we going to import', start=339.12, duration=2.96), FetchedTranscriptSnippet(text=\"restore puns and then you're going to\", start=340.56, duration=3.88), FetchedTranscriptSnippet(text='use this restore Punk function so what', start=342.08, duration=4.28), FetchedTranscriptSnippet(text='this actually does behind the scenes is', start=344.44, duration=4.52), FetchedTranscriptSnippet(text='it uses a model from the hugging face', start=346.36, duration=4.679), FetchedTranscriptSnippet(text='library and this model is actually', start=348.96, duration=4.32), FetchedTranscriptSnippet(text='loaded here and this model is actually', start=351.039, duration=5.961), FetchedTranscriptSnippet(text='pre-trained for taking in bunch of text', start=353.28, duration=6.72), FetchedTranscriptSnippet(text='and then um getting the punctu ation', start=357.0, duration=5.36), FetchedTranscriptSnippet(text='back to that text great now that this is', start=360.0, duration=5.12), FetchedTranscriptSnippet(text=\"done let's move on to the um getting the\", start=362.36, duration=5.16), FetchedTranscriptSnippet(text='results from the punctuation so as you', start=365.12, duration=4.44), FetchedTranscriptSnippet(text='can see right here this one py toch', start=367.52, duration=5.2), FetchedTranscriptSnippet(text='model this model actually got loaded so', start=369.56, duration=4.759), FetchedTranscriptSnippet(text='one thing if you facing some problem', start=372.72, duration=4.36), FetchedTranscriptSnippet(text=\"with GPU it's very important to use this\", start=374.319, duration=6.521), FetchedTranscriptSnippet(text='actually um here yeah as you can see', start=377.08, duration=6.8), FetchedTranscriptSnippet(text='right here we have GPU enable T4 so you', start=380.84, duration=5.84), FetchedTranscriptSnippet(text='need to enable the GPU in your um collab', start=383.88, duration=4.24), FetchedTranscriptSnippet(text=\"otherwise you're going to get an error\", start=386.68, duration=3.639), FetchedTranscriptSnippet(text=\"that is GPU is not available and it's\", start=388.12, duration=4.0), FetchedTranscriptSnippet(text='not really possible to do this without', start=390.319, duration=4.16), FetchedTranscriptSnippet(text='GPU you can do it with CPU as well but', start=392.12, duration=4.76), FetchedTranscriptSnippet(text=\"it's going to be very slow okay so now\", start=394.479, duration=3.56), FetchedTranscriptSnippet(text='that you can see we have loaded the', start=396.88, duration=3.159), FetchedTranscriptSnippet(text='model we have gotten all this vocabulary', start=398.039, duration=3.6), FetchedTranscriptSnippet(text='we have gotten the tokenizer we have', start=400.039, duration=4.0), FetchedTranscriptSnippet(text='gotten the configuration and everything', start=401.639, duration=5.0), FetchedTranscriptSnippet(text=\"so now we are ready to go let's see the\", start=404.039, duration=4.6), FetchedTranscriptSnippet(text='results yeah we are printing out the', start=406.639, duration=4.081), FetchedTranscriptSnippet(text='results as you can see yeah this is as', start=408.639, duration=3.96), FetchedTranscriptSnippet(text=\"you can see it's like very good\", start=410.72, duration=4.24), FetchedTranscriptSnippet(text=\"punctuation I'm an algorithm full stop\", start=412.599, duration=4.081), FetchedTranscriptSnippet(text=\"I've covered log likelihood it which is\", start=414.96, duration=3.56), FetchedTranscriptSnippet(text='kind of a prerequisite full stop then', start=416.68, duration=5.199), FetchedTranscriptSnippet(text=\"comma a du let start it's pretty good\", start=418.52, duration=6.16), FetchedTranscriptSnippet(text=\"not um 100% accurate because it's not a\", start=421.879, duration=5.0), FetchedTranscriptSnippet(text=\"very good model but it's pretty good we\", start=424.68, duration=4.519), FetchedTranscriptSnippet(text='are going to use this okay so the next', start=426.879, duration=5.04), FetchedTranscriptSnippet(text=\"thing that we're going to do is um we're\", start=429.199, duration=4.881), FetchedTranscriptSnippet(text='going to use the chat GPT free version', start=431.919, duration=5.441), FetchedTranscriptSnippet(text='API version to get the results from this', start=434.08, duration=5.04), FetchedTranscriptSnippet(text='transcript so as you can see we have the', start=437.36, duration=3.04), FetchedTranscriptSnippet(text='transcript right here so we know the', start=439.12, duration=3.16), FetchedTranscriptSnippet(text=\"entire content of the video so it's\", start=440.4, duration=3.6), FetchedTranscriptSnippet(text='going to be piece of cake for now sounds', start=442.28, duration=3.52), FetchedTranscriptSnippet(text=\"good yeah so let's see we going to\", start=444.0, duration=3.52), FetchedTranscriptSnippet(text='import open', start=445.8, duration=4.0), FetchedTranscriptSnippet(text=\"AI as you can see I've already install\", start=447.52, duration=3.84), FetchedTranscriptSnippet(text='open a if you have not then you can do', start=449.8, duration=3.679), FetchedTranscriptSnippet(text='it using not equal to pip install open', start=451.36, duration=5.399), FetchedTranscriptSnippet(text='AI to the open AI API key', start=453.479, duration=5.601), FetchedTranscriptSnippet(text='website yeah as you can see right here', start=456.759, duration=5.44), FetchedTranscriptSnippet(text='this has API key you can just log in', start=459.08, duration=4.72), FetchedTranscriptSnippet(text=\"yeah you can just log in here's my API\", start=462.199, duration=3.081), FetchedTranscriptSnippet(text=\"key you can't see that just create a new\", start=463.8, duration=4.04), FetchedTranscriptSnippet(text='secret key write the key permissions all', start=465.28, duration=4.12), FetchedTranscriptSnippet(text='create secret key and you have the API', start=467.84, duration=3.639), FetchedTranscriptSnippet(text=\"key right here it's a it's it's very\", start=469.4, duration=4.759), FetchedTranscriptSnippet(text='easy sounds good now now we have the API', start=471.479, duration=4.44), FetchedTranscriptSnippet(text='key now we are having the', start=474.159, duration=4.48), FetchedTranscriptSnippet(text=\"prompt so let's have the prompt here so\", start=475.919, duration=4.201), FetchedTranscriptSnippet(text=\"as you can see right here let's go over\", start=478.639, duration=3.96), FetchedTranscriptSnippet(text='this so from open we importing open then', start=480.12, duration=4.519), FetchedTranscriptSnippet(text='we have the client with the API key just', start=482.599, duration=4.28), FetchedTranscriptSnippet(text='now we set and now this is the remember', start=484.639, duration=3.721), FetchedTranscriptSnippet(text='this this is very very easy and this is', start=486.879, duration=3.04), FetchedTranscriptSnippet(text='like very standard thing that we going', start=488.36, duration=3.239), FetchedTranscriptSnippet(text='to do so this is the way you have to', start=489.919, duration=4.601), FetchedTranscriptSnippet(text='access the uh openai API so we have the', start=491.599, duration=5.32), FetchedTranscriptSnippet(text='message here roll user content prompt so', start=494.52, duration=3.799), FetchedTranscriptSnippet(text='this is the prompt that we going to pass', start=496.919, duration=3.801), FetchedTranscriptSnippet(text='in um and then we are going to use a', start=498.319, duration=4.521), FetchedTranscriptSnippet(text='model GPT 3.5 turbo because the other', start=500.72, duration=4.12), FetchedTranscriptSnippet(text=\"GPD models are all paid we're not going\", start=502.84, duration=3.319), FetchedTranscriptSnippet(text=\"to use a paid version we're going to use\", start=504.84, duration=3.079), FetchedTranscriptSnippet(text='the free version and we have the', start=506.159, duration=3.961), FetchedTranscriptSnippet(text='temperature set equal to one it controls', start=507.919, duration=4.8), FetchedTranscriptSnippet(text='a Randomness basically Max tokens 2 56', start=510.12, duration=5.039), FetchedTranscriptSnippet(text='is the maximum number of tokens in the', start=512.719, duration=5.12), FetchedTranscriptSnippet(text='response um top P equal to 1 which means', start=515.159, duration=4.601), FetchedTranscriptSnippet(text='the op is a nuclear sampling parameter', start=517.839, duration=4.12), FetchedTranscriptSnippet(text='which is just another thing for uh like', start=519.76, duration=4.6), FetchedTranscriptSnippet(text='temperature just like temperature we we', start=521.959, duration=3.88), FetchedTranscriptSnippet(text='are determining the one with the higher', start=524.36, duration=5.12), FetchedTranscriptSnippet(text='probability Mass um frequency penalty is', start=525.839, duration=5.68), FetchedTranscriptSnippet(text=\"basically zero which means that we don't\", start=529.48, duration=4.64), FetchedTranscriptSnippet(text='want the model to repeat anything and', start=531.519, duration=4.241), FetchedTranscriptSnippet(text='prence penalty is also zero which means', start=534.12, duration=2.92), FetchedTranscriptSnippet(text='that we do not want it to add', start=535.76, duration=3.68), FetchedTranscriptSnippet(text='unnecessary words or just making it for', start=537.04, duration=3.96), FetchedTranscriptSnippet(text='veros without any reason for example if', start=539.44, duration=3.079), FetchedTranscriptSnippet(text=\"you're asking for one word just reply\", start=541.0, duration=4.36), FetchedTranscriptSnippet(text=\"with one word don't be any like verbos\", start=542.519, duration=4.681), FetchedTranscriptSnippet(text=\"and explain why you're saying that and\", start=545.36, duration=4.84), FetchedTranscriptSnippet(text=\"all that you don't want that right um so\", start=547.2, duration=4.199), FetchedTranscriptSnippet(text=\"let's run\", start=550.2, duration=3.4), FetchedTranscriptSnippet(text='this great now we have the response', start=551.399, duration=3.88), FetchedTranscriptSnippet(text='right here simple thing just print it', start=553.6, duration=3.44), FetchedTranscriptSnippet(text='out so this is the way you can print out', start=555.279, duration=3.721), FetchedTranscriptSnippet(text='the response is very important chat', start=557.04, duration=4.68), FetchedTranscriptSnippet(text='completion. choices z. message. content', start=559.0, duration=4.64), FetchedTranscriptSnippet(text='this is the way it actually comes in so', start=561.72, duration=3.2), FetchedTranscriptSnippet(text='if you want to see what the chat', start=563.64, duration=2.8), FetchedTranscriptSnippet(text='completion looks like you can check it', start=564.92, duration=3.8), FetchedTranscriptSnippet(text=\"out it's actually kind of a dictionary\", start=566.44, duration=4.28), FetchedTranscriptSnippet(text=\"uh it's kind of a class here where you\", start=568.72, duration=4.32), FetchedTranscriptSnippet(text='have different attributes so this is the', start=570.72, duration=4.84), FetchedTranscriptSnippet(text='content that we want um so that is why', start=573.04, duration=4.56), FetchedTranscriptSnippet(text=\"we are doing this so let's see the\", start=575.56, duration=3.399), FetchedTranscriptSnippet(text='content so the test discusses the', start=577.6, duration=3.08), FetchedTranscriptSnippet(text='derivation and maths focusing on binary', start=578.959, duration=4.681), FetchedTranscriptSnippet(text='classification perfect destion boundary', start=580.68, duration=4.719), FetchedTranscriptSnippet(text='uh like likelihood function sigmoid', start=583.64, duration=4.199), FetchedTranscriptSnippet(text='function gradient descent optimal', start=585.399, duration=4.12), FetchedTranscriptSnippet(text='parameters like Theta it controls by', start=587.839, duration=3.801), FetchedTranscriptSnippet(text='discussing how to determine the equation', start=589.519, duration=4.121), FetchedTranscriptSnippet(text='in theeta transpose X comprehensive', start=591.64, duration=3.92), FetchedTranscriptSnippet(text='explanation and its implementation so', start=593.64, duration=4.759), FetchedTranscriptSnippet(text=\"well it's your cue to go and study this\", start=595.56, duration=6.12), FetchedTranscriptSnippet(text='classification um video as well but yeah', start=598.399, duration=4.761), FetchedTranscriptSnippet(text=\"you can do it at your own pace but it's\", start=601.68, duration=3.88), FetchedTranscriptSnippet(text='a very important thing as well sorry not', start=603.16, duration=4.64), FetchedTranscriptSnippet(text='sorry a little bit of promotion but yeah', start=605.56, duration=4.2), FetchedTranscriptSnippet(text='now we done so now you can just take on', start=607.8, duration=4.52), FetchedTranscriptSnippet(text='a prompt which is any kind of prompt', start=609.76, duration=4.639), FetchedTranscriptSnippet(text=\"that you want uh why don't why just\", start=612.32, duration=5.36), FetchedTranscriptSnippet(text=\"change this let's just have this one\", start=614.399, duration=5.801), FetchedTranscriptSnippet(text=\"right here so let's change it to I don't\", start=617.68, duration=4.44), FetchedTranscriptSnippet(text='know anything you want', start=620.2, duration=5.759), FetchedTranscriptSnippet(text='maybe um', start=622.12, duration=3.839), FetchedTranscriptSnippet(text='answer questions based on', start=626.44, duration=5.959), FetchedTranscriptSnippet(text=\"this text you have right here so let's\", start=629.959, duration=5.68), FetchedTranscriptSnippet(text='add a question um what do you want me to', start=632.399, duration=5.841), FetchedTranscriptSnippet(text=\"add let's\", start=635.639, duration=6.44), FetchedTranscriptSnippet(text='say what is', start=638.24, duration=3.839), FetchedTranscriptSnippet(text='classification what is exactly taught', start=644.6, duration=4.32), FetchedTranscriptSnippet(text=\"here let's see what it has to say\", start=649.48, duration=6.359), FetchedTranscriptSnippet(text='algorithm predict the class speaker well', start=653.16, duration=4.56), FetchedTranscriptSnippet(text=\"it's not my name but whatever we have\", start=655.839, duration=4.12), FetchedTranscriptSnippet(text='put it in the transcript so derivation', start=657.72, duration=3.96), FetchedTranscriptSnippet(text='and math specifically binary', start=659.959, duration=4.12), FetchedTranscriptSnippet(text='classification uh okay my gender is also', start=661.68, duration=5.279), FetchedTranscriptSnippet(text='wrong but whatever decision boundary and', start=664.079, duration=5.241), FetchedTranscriptSnippet(text='then dering the this one radiant descent', start=666.959, duration=4.841), FetchedTranscriptSnippet(text='see is perfect the answer is perfect key', start=669.32, duration=4.92), FetchedTranscriptSnippet(text='Concepts it um and steps involving', start=671.8, duration=4.2), FetchedTranscriptSnippet(text='binary classification retailed', start=674.24, duration=3.2), FetchedTranscriptSnippet(text='description as you can see this is', start=676.0, duration=3.48), FetchedTranscriptSnippet(text='extremely good um I also show you how', start=677.44, duration=3.519), FetchedTranscriptSnippet(text='you can deploy this from n to end but', start=679.48, duration=3.84), FetchedTranscriptSnippet(text=\"that's for another video okay take care\", start=680.959, duration=4.801), FetchedTranscriptSnippet(text='bye', start=683.32, duration=2.44)], video_id='xDQL3vWwcp0', language='English (auto-generated)', language_code='en', is_generated=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6205358e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_joined = \" \".join([snippet.text for snippet in transcript.snippets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe313b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"hello everyone I am Santi and I'm currently working as an ml engineer today we are going to do an awesome machine learning project that you can add to your resume and impress all the interviewers um I'm dedicated to teaching machine learning to all of you and to ensure that you all learned an ml job as soon as possible okay so without any further Ado let's Dive Right In so our title is going to be um so our project title is going to be uh YouTube video summarizer with llm well so what's going to do is going to take in a video and you can ask any question regarding the videos contents the images Etc and that's going to be really really good really useful as well and that can be a mini deployed project as well okay so first things first um let's let's let's think about why do we need this in the first place the interviewer might say why not just use chat GPT right because chat gpg has now enabled the search web feature for every free user right so you might be wondering why not just use that okay so let's see why we are not going to use that as you can see right here we have our chat GPT open and let's see um which video are we going to use yeah so this is a video that we are going to use right here as you can see my binary classification video which is of the length of 32 32 minutes okay so let's put this inside the chat GPD and I will the search web feature and say write the transcript for this this for this video because first of all we'll need the transcript right as you can see right here it says that it's unable to actually get the video um transcript so if you don't have the transcript obviously then you won't be able to do anything with it right okay whenever you get any project it's very important to understand that you first need to break the project down into smaller pieces that you can tackle easily this is very important because if you think that how how am I going to do that we don't have this we don't have that at the first so this going to be very confusing so let's tackle it one by one step by step remember this for any project that you are going to do okay I'm going to use Google collab here because we need GPU for our support so if you don't have GPU on your system or you're using any Windows system you're using a Mac system whatever it is it doesn't matter as long as you have Google collab you can just go in it's free for you to use and you can do the project here and in your resume you can just put in link okay so let's do first install let's first install the YouTube transcript API great now we have the YouTube trans transcript API so now what we going to do is basically get the link provide the link to the video um to this library and generate the transcript using this now we're going to import the YouTube transcript API so from YouTube YouTube transcript API sounds good now let's get the video ID from the um video so what we going to do is basically as you know this is the video right here and this is the video ID so whenever you put in a link you're going to get the video ID from here get video ID is going to be this function great you now have the video ID so let's see what the video ID looks like um copy this yeah this is the video ID yeah next thing is getting the transcript so basically get video ID we already have that so let's just store it in a variable this one going to be video ID um yeah sounds good now let's see what the transcript looks like yeah as you can see this is what the transcript looks like so now what you're going to do is uh add all this together yep yeah so now what we going to do is do the transcript join so what does it going to look like exactly just join this together all the text features that you have in this transcript great now we can see what the transcript joint looks like yeah great as you can see right here this is our transcript that we have um okay as you can see we have it Santi but we can't do anything about it so let's just forget about it for the moment yeah um sounds good now what we going to do is basically we need to as you can see the transcript that you saw um it does not actually have a proper punctuation so we going to put in the punctuation now how we're going to do that we're going to use a model for that this is where the llm comes into the play okay so now as you can see like uh restoring the punctuation this is called a library which we have actually and this is actually a restore Punk Library yeah this is our Punk library that we have actually but there's a problem out here the versions are very like old because it's three years ago so that is why there's a patch for the Same by another uh GitHub user so that that is what we are going to use here great so this is actually the thing please note it down because you're going to need this if you use the normal ARB it's not going to help great now the next thing comes is restoring the punctuations so from the r pun we going to import restore puns and then you're going to use this restore Punk function so what this actually does behind the scenes is it uses a model from the hugging face library and this model is actually loaded here and this model is actually pre-trained for taking in bunch of text and then um getting the punctu ation back to that text great now that this is done let's move on to the um getting the results from the punctuation so as you can see right here this one py toch model this model actually got loaded so one thing if you facing some problem with GPU it's very important to use this actually um here yeah as you can see right here we have GPU enable T4 so you need to enable the GPU in your um collab otherwise you're going to get an error that is GPU is not available and it's not really possible to do this without GPU you can do it with CPU as well but it's going to be very slow okay so now that you can see we have loaded the model we have gotten all this vocabulary we have gotten the tokenizer we have gotten the configuration and everything so now we are ready to go let's see the results yeah we are printing out the results as you can see yeah this is as you can see it's like very good punctuation I'm an algorithm full stop I've covered log likelihood it which is kind of a prerequisite full stop then comma a du let start it's pretty good not um 100% accurate because it's not a very good model but it's pretty good we are going to use this okay so the next thing that we're going to do is um we're going to use the chat GPT free version API version to get the results from this transcript so as you can see we have the transcript right here so we know the entire content of the video so it's going to be piece of cake for now sounds good yeah so let's see we going to import open AI as you can see I've already install open a if you have not then you can do it using not equal to pip install open AI to the open AI API key website yeah as you can see right here this has API key you can just log in yeah you can just log in here's my API key you can't see that just create a new secret key write the key permissions all create secret key and you have the API key right here it's a it's it's very easy sounds good now now we have the API key now we are having the prompt so let's have the prompt here so as you can see right here let's go over this so from open we importing open then we have the client with the API key just now we set and now this is the remember this this is very very easy and this is like very standard thing that we going to do so this is the way you have to access the uh openai API so we have the message here roll user content prompt so this is the prompt that we going to pass in um and then we are going to use a model GPT 3.5 turbo because the other GPD models are all paid we're not going to use a paid version we're going to use the free version and we have the temperature set equal to one it controls a Randomness basically Max tokens 2 56 is the maximum number of tokens in the response um top P equal to 1 which means the op is a nuclear sampling parameter which is just another thing for uh like temperature just like temperature we we are determining the one with the higher probability Mass um frequency penalty is basically zero which means that we don't want the model to repeat anything and prence penalty is also zero which means that we do not want it to add unnecessary words or just making it for veros without any reason for example if you're asking for one word just reply with one word don't be any like verbos and explain why you're saying that and all that you don't want that right um so let's run this great now we have the response right here simple thing just print it out so this is the way you can print out the response is very important chat completion. choices z. message. content this is the way it actually comes in so if you want to see what the chat completion looks like you can check it out it's actually kind of a dictionary uh it's kind of a class here where you have different attributes so this is the content that we want um so that is why we are doing this so let's see the content so the test discusses the derivation and maths focusing on binary classification perfect destion boundary uh like likelihood function sigmoid function gradient descent optimal parameters like Theta it controls by discussing how to determine the equation in theeta transpose X comprehensive explanation and its implementation so well it's your cue to go and study this classification um video as well but yeah you can do it at your own pace but it's a very important thing as well sorry not sorry a little bit of promotion but yeah now we done so now you can just take on a prompt which is any kind of prompt that you want uh why don't why just change this let's just have this one right here so let's change it to I don't know anything you want maybe um answer questions based on this text you have right here so let's add a question um what do you want me to add let's say what is classification what is exactly taught here let's see what it has to say algorithm predict the class speaker well it's not my name but whatever we have put it in the transcript so derivation and math specifically binary classification uh okay my gender is also wrong but whatever decision boundary and then dering the this one radiant descent see is perfect the answer is perfect key Concepts it um and steps involving binary classification retailed description as you can see this is extremely good um I also show you how you can deploy this from n to end but that's for another video okay take care bye\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57d83186",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b5fd863c184f9189847c532700d277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5847ee2cc7f465f8ae82fa7d0b1c697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92edc89e037d4da68bf3e6ba6d8d059a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/530 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77b5161205b14794a22b7730987cfcdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6660a80e96664bf48724c773e98afedd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86319ba7d4e3441996272772f302cb17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rpunct=RestorePuncts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3164e9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/simpletransformers/ner/ner_model.py:1653: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Everyone! I am Santi and I'm currently working as an Ml engineer. Today We are going to do an awesome machine learning project that you can add to your resume and impress all the interviewers. Um, I'm dedicated to teaching machine learning to all of you and to ensure that you all learned an Ml job as soon as possible. Okay, so without any further, Ado Let's Dive Right In So our title is going to be Um, so our project title is going to be uh YouTube Video summarizer with Llm. Well, so what's going to do is going to take in a video and you can ask any question regarding the videos contents, the images Etc and that's going to be really, really good. Really useful as well and that can be a mini deployed project as well. Okay, so first things first. Um, let's let's let's think about why do we need this in the first place? The interviewer might say, why not just use chat GPT right? Because Chat Gpg has now enabled the search web feature for every free user, right? So you might be wondering, why not just use that? Okay, so let's see why we are not going to use that As you can see right here we have our chat GPT open and let's see um, which video are we going to use. Yeah, so this is a video that we are going to use right here as you can see my binary classification video which is of the length of 32 32 minutes. Okay, so let's put this inside the chat GPD and I will the search web feature and say write the transcript for this. This for this video because first of all, we'll need the transcript right. As you can see right here, it says that it's unable to actually get the video um transcript. So if you don't have the transcript obviously then you won't be able to do anything with it, right? Okay, whenever you get any project, it's very important to understand that you first need to break the project down into smaller pieces that you can tackle easily. This is very important because if you think that how how am I going to do that, we don't have this. We don't have that at the first so this going to be very confusing. So let's tackle it one by one. step by step. Remember this for any project that you are going to do Okay I'm going to use Google Collab here because we need GPU for our support. So if you don't have GPU on your system or you're using any Windows system, you're using a Mac system. Whatever it is, it doesn't matter. As long as you have Google collab, you can just go in. It's free for you to use and you can do the project here and in your resume. you can just put in link. Okay, so let's do first install. Let's first install the YouTube transcript API Great! Now we have the YouTube trans transcript API So now what we going to do is basically get the link, provide the link to the video, um to this library and generate the transcript using this. Now we're going to import the YouTube transcript API So from YouTube YouTube Transcript API Sounds good. Now let's get the video ID from the Um video. So what we going to do is basically as you know, this is the video right here and this is the video. ID So whenever you put in a link, you're going to get the video ID From here, get video ID Is going to be this function great. You now have the video ID So let's see what the video ID looks like. Um, copy this. Yeah, this is the video ID Yeah, Next thing is getting the transcript. So basically get video ID We already have that. so let's just store it in a variable. This one going to be video ID Um yeah, sounds good. Now let's see what the transcript looks like. Yeah, as you can see, this is what the transcript looks like. So now what you're going to do is uh, add all this together. Yep, yeah. So now what we going to do is do the transcript join. So what does it going to look like Exactly, Just join this together all the text features that you have in this transcript. Great! Now we can see what the transcript joint looks like. Yeah, great as you can see right here this is our transcript that we have. Um okay as you can see, we have it Santi But we can't do anything about it so let's just forget about it for the moment. Yeah, um sounds good. Now what we going to do is basically we need to as you can see the transcript that you saw um, it does not actually have a proper punctuation. So we going to put in the punctuation. Now how we're going to do that, We're going to use a model for that. This is where the Llm comes into the play. Okay so now as you can see like uh, restoring the punctuation, this is called a library which we have actually and this is actually a Restore Punk Library Yeah, this is our Punk library that we have actually, but there's a problem out here. The versions are very like old because it's three years ago. So that is why there's a patch for the Same by another uh GitHub user. so that that is what we are going to use here. Great! So this is actually the thing. Please note it down because you're going to need this if you use the normal ARB it's not going to help great. Now the next thing comes is restoring the punctuations. So from the r pun we going to import restore puns and then you're going to use this restore Punk function. So what this actually does behind the scenes is it uses a model from the Hugging Face library and this model is actually loaded here and this model is actually pre-trained for taking in bunch of text and then um getting the punctu ation back to that text. Great! Now that this is done, let's move on to the Um getting the results from the punctuation. So as you can see right here this one Py Toch model, this model actually got loaded. So one thing if you facing some problem with GPU it's very important to use this actually. Um here. Yeah, as you can see right here we have GPU enable T4 So you need to enable the GPU in your Um collab. otherwise you're going to get an error that is GPU is not available and it's not really possible to do this without GPU You can do it with CPU as well but it's going to be very slow. Okay so now that you can see we have loaded the model, We have gotten all this vocabulary, We have gotten the tokenizer, we have gotten the configuration and everything so now we are ready to go. Let's see the results. Yeah we are printing out the results as you can see. Yeah this is as you can see it's like very good punctuation. I'm an algorithm full stop I've covered log likelihood it which is kind of a prerequisite full stop then comma a du Let start it's pretty good. Not um 100% accurate because it's not a very good model. but it's pretty good. We are going to use this. Okay so the next thing that we're going to do is um we're going to use the chat GPT free version API version to get the results from this transcript. So as you can see we have the transcript right here so we know the entire content of the video so it's going to be piece of cake for now. Sounds good? Yeah so let's see we going to import Open AI as you can see I've already install Open A If you have not then you can do it using not equal to pip install Open AI to the Open AI API Key Website Yeah as you can see right here this has API key. You can just log in. Yeah you can just log in. Here's my API key. You can't see that. Just create a new secret key, write the key, permissions all create secret key and you have the API key right here. It's A It's it's very easy. Sounds good. Now Now we have the API key. Now we are having the prompt so let's have the prompt here. So as you can see right here let's go over this. So from open we importing open then we have the client with the API key. Just now we set and now this is the remember this This is very very easy and this is like very standard thing that we going to do. So this is the way you have to access the Uh Openai API So we have the message here: roll user content prompt. So this is the prompt that we going to pass in. Um and then we are going to use a model GPT 3.5 turbo. Because the other GPD models are all paid, we're not going to use a paid version. We're going to use the free version and we have the temperature set equal to one. It controls a Randomness Basically Max Tokens 2 56 is the maximum number of tokens in the response. um top P equal to 1 Which means the Op is a nuclear sampling parameter which is just another thing for uh, like temperature. Just like temperature, we we are determining the one with the higher probability Mass um. Frequency penalty is basically zero, which means that we don't want the model to repeat anything. and prence penalty is also zero. Which means that we do not want it to add unnecessary words or just making it for Veros without any reason. For example, if you're asking for one word, just reply with one word. don't be any like verbos and explain why you're saying that and all that you don't want that right? Um, so let's run this great. Now we have the response right here. Simple thing: just print it out. So this is the way you can print out. The response is very important. Chat completion. choices, Z. message. content. This is the way it actually comes in. so if you want to see what the chat completion looks like, you can check it out. It's actually kind of a dictionary. Uh, it's kind of a class here where you have different attributes. so this is the content that we want. Um, so that is why we are doing this. So let's see the content. So the test discusses the derivation and maths, focusing on binary classification. Perfect destion boundary uh, like likelihood function, sigmoid function, gradient descent, optimal parameters like Theta It controls by discussing how to determine the equation in theeta transpose X Comprehensive explanation and its implementation so well. it's your cue to go and study this classification. um, video as well. But yeah, you can do it at your own pace. but it's a very important thing as well. Sorry, not sorry. a little bit of promotion, but yeah, now we done. So now you can just take on a prompt which is any kind of prompt that you want. Uh, why don't Why just change this? Let's just have this one right here. So let's change it to: I Don't know anything you want? Maybe, um, answer questions based on this text you have right here. So let's add a question. Um, what do you want me to add? Let's say what is classification? What is exactly taught here? Let's see what it has to say. Algorithm: Predict the class Speaker: Well, it's not my name, but whatever we have put it in the transcript. So derivation and math specifically binary classification. Uh okay, my gender is also wrong, but whatever. decision boundary and then dering the this one radiant descent see is perfect. The answer is perfect. Key: Concepts It: Um and steps involving binary classification retailed Description: As you can see, this is extremely good. Um I Also, show you how you can deploy this from n to end but that's for another video. Okay, take care bye.\n"
     ]
    }
   ],
   "source": [
    "results = rpunct.punctuate(transcript_joined)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32fb60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key='YOUR_API_KEY_HERE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "15d290a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "#role : you are a helpful study buddy assistant who summarizes Youtube/Lecture video transcripts.\n",
    "#tasks: Summarize texts and try to identify tasks in the text and provide them as a todo list if there is any.\n",
    "Summarize the following text:\\n\\n{results}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "611d469f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"qwen/qwen3-coder:free\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04a04b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## YouTube Video Summarizer with LLM - Project Summary\n",
      "\n",
      "This project creates a YouTube video summarizer using Large Language Models (LLMs) that can answer questions about video content. The key motivation is that while ChatGPT has web search features, it often cannot retrieve transcripts from YouTube videos directly, making this tool useful for extracting and processing video content.\n",
      "\n",
      "### Main Components:\n",
      "1. **Video Transcript Extraction**: Uses YouTube Transcript API to extract video content\n",
      "2. **Text Processing**: Implements punctuation restoration using pre-trained models from Hugging Face\n",
      "3. **LLM Integration**: Utilizes OpenAI's GPT-3.5 Turbo API for summarization and question-answering\n",
      "4. **Deployment Ready**: Can be built as a deployable mini-project\n",
      "\n",
      "### Key Technical Steps:\n",
      "- Extract video ID from YouTube URLs\n",
      "- Generate video transcripts using YouTube Transcript API\n",
      "- Restore proper punctuation using pre-trained language models\n",
      "- Integrate with OpenAI API for content processing\n",
      "- Configure API parameters (temperature, tokens, penalties) for optimal responses\n",
      "\n",
      "## TODO List:\n",
      "\n",
      "1. [ ] Set up Google Colab environment with GPU enabled\n",
      "2. [ ] Install required libraries:\n",
      "   - YouTube Transcript API\n",
      "   - OpenAI library\n",
      "   - Punctuation restoration library with GitHub patch\n",
      "3. [ ] Obtain OpenAI API key from OpenAI website\n",
      "4. [ ] Implement video ID extraction function\n",
      "5. [ ] Create transcript generation pipeline using YouTube Transcript API\n",
      "6. [ ] Implement punctuation restoration using Hugging Face models\n",
      "7. [ ] Configure OpenAI API client with proper parameters\n",
      "8. [ ] Create prompt templates for summarization and Q&A functionality\n",
      "9. [ ] Test video processing workflow with sample YouTube video\n",
      "10. [ ] Deploy the complete application as a mini-project\n",
      "11. [ ] Document the project for resume/portfolio inclusion\n"
     ]
    }
   ],
   "source": [
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9464624a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
